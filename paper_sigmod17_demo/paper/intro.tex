\section{Introduction}
%\dan{7 pages}
\label{sec:introduction}

%\dan{this part is mostly done, only minor edits needed}

% Big data is used today in a wide range of domains, such as natural
% sciences (physics CITE, astronomy CITE, genomics CITE, biology CITE),
% social science and in particular measurements of human activity
% (e.g. recommendation CITE, personalization CITE),
% education~\cite{clauset-2015}, marketing and economics CITE, and MORE
% HERE.  The most successful type of application of Big data is {\em
%   predictive}: the data available, the \emph{seen} data, is used to
% infer a model that can predict features and trends of data that is not
% available, the \emph{unseen} data.  This potential for predictive
% analysis has generated the huge interest we see today in Big data, and
% has, in some sense, democratized data, by stimulating a huge number of
% ``data enthusiasts'' to collect, explore, analyze, integrate, and
% visualize data.  The term Big data is often used today to refer not
% just to the traditional features like volume, variety, velocity, but
% also to its wide availability to a broad range of users.


% lg1 - original commentout below at end; take care as this can lead to confusion
Most data driven decisions today are based on purely predictive
analytics, which only finds associational dependencies and
correlations.  The danger is that naive data enthusiasts will
incorrectly interpret these predictive models as causal. While the distinction between causal and predictive analysis has
 been recognized, the conflation between the two is common which results in false discovery claims.
\ignore{
Much of the success of Big data today comes from
  \emph{descriptive analytics}: statistical models or data mining algorithms applied to data
  to predict new or future observations, e.g., we observe how users click on ads, then build a model and predict how future
  users will click.
Predictive analysis/modeling is central to many scientific fields, such as bioinformatics and natural language processing,
  in other  fields - such as social economics, psychology, education and environmental science - researchers are focused
  on testing and evaluating {\em causal hypotheses}.
While the distinction between causal and predictive analysis has been recognized, the conflation between the two is common.}

\ignore{
Both predictive and causal analysis are needed to generate and test theories,
  policy and decision making and to evaluate hypotheses, yet each plays a different role in doing so.
In fact, performing predictive analysis to address questions that are causal in nature could lead to a flood of false discovery claims.
In many cases, researchers who want to discover causality from data analysis settle for predictive analysis either because they think it is causal or lack of available alternatives.
}
Causal inference has been studied extensively in statistics and
computer science \cite{Fisher1935design,Rubin2005,holland1986statistics,PearlBook2000\ignore{,Spirtes:book01}}.

Many toolkits have been developed for performing causal inference in statistical software such as R, e.g., MatchIt and CEM \cite{ho2005,iacus2009cem}.  However, these toolkits do not scale to large datasets. For example, performing causal inference  on a dataset with 10M entries takes several hours using MatchIt or CEM.
 Additionally, causal analysis is part of a larger pipeline that includes data acquisition, data cleaning, and data integration; for large datasets, these tasks are best handled by a relational database engine, which provides most of the functionality needed for these tasks, and also scales up to large datasets. %% \dans{the previous sentence is cumbersome.  what we want to say is that causal analysis is part of a larger pipeline that includes data acquisition, data cleaning, and data integration; for large datasets, these tasks are best handled by a relational database engine, which provides most of the functionality needed for these tasks, and also scales up to large datasets.}
\ignore{A rich ecosystem of tools and organizational requirements further encourage SQL database storage. Transferring
data from DBMS to statistical softwares or connecting these
softwares to DBMS can be error prone, difficult, time consuming and inefficient. For these
cases, it would be helpful to push statistical methods for causal inference into the DBMS.
\ignore{\corey{should go over the scalability / current tool problem here before jumping into the} solution?}}

We argue that \emph{causal inference is a data management problem}.
In this demonstration, we propose \GSQL,\footnote{ The prefix Zali refers to
  al-Ghzali (1058-1111), a medieval Persian philosopher. It is known
  that David Hume (1711-1776), a Scottish philosopher, who gave the
  first explicit definition of causation in terms of counterfactuals,
  was heavily influenced by al-Ghzali's conception of causality
  \cite{shalizi2013advanced}.}
  a SQL-based framework for drawing causal inference within DBMS. \GSQL\ takes the first step towards truly scalable causal inference by modeling it as a data management problem. We demonstrate that
   approaching causal inference from this fresh perspective is key to scalability and robustness.  \GSQL\ supports state-of-the-art methods for causal inference and runs at scale within a database engine.   The framework \ignore{is designed and implemented as an extension for PostgreSQL object-relational database
systems and} includes a series of optimization techniques that allow it to
scale to billions of records.

